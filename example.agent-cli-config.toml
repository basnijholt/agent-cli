# Example configuration for agent-cli
# Copy this file to ~/.config/agent-cli/config.toml or ./agent-cli-config.toml and edit
#
# This file demonstrates how to configure all available options.
# Keys use dashes to match the command-line arguments.
# Any option here can be overridden by a command-line argument.

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# --- Default Settings ---
# These settings apply to all commands unless overridden in a command-specific
# section below.
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[defaults]

# --- Provider Selection ---
# Select the default provider for each service.
# LLM: "ollama", "openai", or "gemini"
# ASR: "wyoming" or "openai"
# TTS: "wyoming", "openai", or "kokoro"
llm-provider = "ollama"
tts-provider = "wyoming"

# --- API Keys ---
# Your OpenAI API key. Can also be set via the OPENAI_API_KEY environment variable.
openai-api-key = "sk-..."
# gemini-api-key = "..."

# --- Audio Device Settings ---
# Specify partial device names (comma-separated). First match wins.
# Use `agent-cli speak --list-devices` to see available devices.
input-device-name = "webcam,logitech,airpods,macbook"
output-device-name = "speakers,airpods,macbook"
# Or specify by index (less stable across reboots):
# input-device-index = 1
# output-device-index = 1

# --- LLM Settings ---
# Ollama (local or remote server)
llm-ollama-model = "gemma3:4b"
llm-ollama-host = "http://localhost:11434"
# For remote Ollama server on your network:
# llm-ollama-host = "http://192.168.1.100:11434"

# OpenAI (or OpenAI-compatible APIs like llama.cpp, vLLM, etc.)
llm-openai-model = "gpt-4o-mini"
# For llama-server or other OpenAI-compatible local servers:
# openai-base-url = "http://localhost:8080/v1"
# llm-openai-model = "my-local-model"

# --- ASR (Speech-to-Text) Settings ---
# Wyoming Faster Whisper (local or remote)
asr-wyoming-ip = "localhost"
asr-wyoming-port = 10300
# For remote Wyoming server:
# asr-wyoming-ip = "192.168.1.100"

# OpenAI Whisper
asr-openai-model = "whisper-1"
# Custom OpenAI-compatible Whisper endpoint:
# asr-provider = "openai"
# asr-openai-base-url = "http://localhost:9898"
# asr-openai-model = "nvidia/canary-qwen-2.5b"
# asr-openai-prompt = "Transcribe the following:"

# --- TTS (Text-to-Speech) Settings ---
# Wyoming Piper (local or remote)
tts-wyoming-ip = "localhost"
tts-wyoming-port = 10200
tts-wyoming-voice = "en_US-lessac-medium"
# tts-wyoming-language = "en_US"
# tts-wyoming-speaker = "speaker_name"

# OpenAI TTS
tts-openai-model = "tts-1"
tts-openai-voice = "alloy"
# tts-openai-base-url = "http://localhost:8000/v1"

# Kokoro TTS (high-quality local TTS)
# tts-provider = "kokoro"
# tts-kokoro-host = "http://localhost:8880/v1"
# tts-kokoro-voice = "af_bella"

# --- RAG & Memory Settings ---
# Embedding model for RAG and memory features
# embedding-model = "text-embedding-3-small"  # OpenAI
# embedding-model = "nomic-embed-text"  # Ollama

# --- General Behavior ---
log-level = "WARNING"
# log-file = "~/.config/agent-cli/agent-cli.log"
quiet = false
clipboard = true


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# --- Command-Specific Overrides ---
# Settings in these sections will override the [defaults] for that specific
# command.
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[assistant]
# Wake-word detection settings
wake-server-ip = "localhost"
wake-server-port = 10400
wake-word = "ok_nabu"  # Options: "ok_nabu", "hey_jarvis", "alexa", "hey_mycroft"
# For remote wake-word server:
# wake-server-ip = "192.168.1.100"
tts = true

[autocorrect]
# Use a more powerful model specifically for the autocorrect command.
llm-provider = "ollama"
llm-ollama-model = "devstral:24b"

[chat]
# By default, chat uses local providers.
# For better tool use, you might want to switch to OpenAI:
# llm-provider = "openai"
# tts-provider = "openai"
# llm-openai-model = "gpt-4-turbo"
tts = true
tts-speed = 1.2
# Conversation history settings
history-dir = "~/.config/agent-cli/history"
last-n-messages = 50 # Number of messages to load from history

[speak]
# Use a specific voice for the speak command.
tts-provider = "wyoming"
tts-wyoming-voice = "en_US-ryan-high"
tts-speed = 1.0

[transcribe]
# For higher accuracy, switch to OpenAI:
# asr-provider = "openai"
# llm-provider = "openai"

# Enable LLM to clean up the transcript (fix punctuation, formatting, etc.)
llm = true

# Custom instructions for the LLM to improve transcription quality.
# Add domain-specific terms, formatting preferences, or context.
extra-instructions = """
Assume the user is often discussing Python programming.
Use backticks for variable names, function names, and other code elements.
Follow PEP8: use `snake_case` for variables, functions, and package names; `CamelCase` for classes.
Frequently used terms: `FastAPI`, `async/await`, `pytest`, `pre-commit`.
"""

# Log all transcriptions with timestamps for later reference
transcription-log = "~/.config/agent-cli/transcription.log"

[voice-edit]
# Use a powerful local model for the voice assistant.
llm-provider = "ollama"
llm-ollama-model = "llama3"
tts = true
