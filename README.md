# AI Assistant

`ai-assistant` is a Python command-line tool that provides a suite of AI-powered utilities.

> [!TIP]
> If using [`uv`](https://docs.astral.sh/uv/), you can easily run the tools from this package directly. For example, to see the help message for `autocorrect`:
>
> ```bash
> uvx ai-assistant autocorrect --help
> ```

<details><summary><b><u>[ToC]</u></b> 📚</summary>

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
  - [`autocorrect`](#autocorrect)
  - [`transcribe`](#transcribe)
  - [`voice-assistant`](#voice-assistant)
- [Development](#development)
  - [Running Tests](#running-tests)
  - [Pre-commit Hooks](#pre-commit-hooks)
- [Contributing](#contributing)
- [License](#license)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

</details>

## Features

- **`autocorrect`**: Correct grammar and spelling in your text using a local LLM with Ollama.
- **`transcribe`**: Transcribe audio files to text.
- **`voice-assistant`**: A voice-powered clipboard assistant.

## Prerequisites

- **Python**: Version 3.11 or higher.
- **Ollama**: For `autocorrect`, you need [Ollama](https://ollama.ai/) running with a model pulled (e.g., `ollama pull llama2`).

## Installation

Install `ai-assistant` using pip:

```bash
pip install ai-assistant
```

Or for development:

1. **Clone the repository:**

   ```bash
   git clone git@github.com:basnijholt/ai-assistant.git
   cd ai-assistant
   ```

2. **Install in development mode:**

   ```bash
   uv sync
   source .venv/bin/activate  # On Windows use `.venv\Scripts\activate`
   ```

## Usage

This package provides multiple command-line tools.

### `autocorrect`

Corrects text from your clipboard or direct input.

<details>
<summary>See the output of <code>autocorrect --help</code></summary>

<!-- CODE:BASH:START -->
<!-- echo '```yaml' -->
<!-- export NO_COLOR=1 -->
<!-- export TERM=dumb -->
<!-- autocorrect --help -->
<!-- echo '```' -->
<!-- CODE:END -->

<!-- OUTPUT:START -->
<!-- ⚠️ This content is auto-generated by `markdown-code-runner`. -->
```yaml
```

<!-- OUTPUT:END -->

</details>

### `transcribe`

Transcribes an audio file.

<details>
<summary>See the output of <code>transcribe --help</code></summary>

<!-- CODE:BASH:START -->
<!-- echo '```yaml' -->
<!-- export NO_COLOR=1 -->
<!-- export TERM=dumb -->
<!-- transcribe --help -->
<!-- echo '```' -->
<!-- CODE:END -->

<!-- OUTPUT:START -->
<!-- ⚠️ This content is auto-generated by `markdown-code-runner`. -->
```yaml
usage: transcribe [-h] [--log-level {DEBUG,INFO,WARNING,ERROR}]
                  [--log-file LOG_FILE] [-q] [--device-index DEVICE_INDEX]
                  [--list-devices] [--asr-server-ip ASR_SERVER_IP]
                  [--asr-server-port ASR_SERVER_PORT] [--clipboard]

Wyoming ASR Client for streaming microphone audio to a transcription server.

options:
  -h, --help            show this help message and exit
  --log-level {DEBUG,INFO,WARNING,ERROR}
                        Set logging level.
  --log-file LOG_FILE   Path to a file to write logs to.
  -q, --quiet           Suppress console output from rich.
  --device-index DEVICE_INDEX
                        Index of the PyAudio input device to use.
  --list-devices        List available audio input devices and exit.
  --asr-server-ip ASR_SERVER_IP
                        Wyoming ASR server IP address.
  --asr-server-port ASR_SERVER_PORT
                        Wyoming ASR server port.
  --clipboard           Copy transcript to clipboard (default: True).
```

<!-- OUTPUT:END -->

</details>

### `voice-assistant`

Starts the voice assistant. Supports daemon mode with process management.

**Basic Usage:**
```bash
# Run in foreground
voice-assistant --device-index 1

# Run as daemon (background)
voice-assistant --daemon --device-index 1 --quiet

# Check daemon status
voice-assistant --status

# Stop daemon
voice-assistant --kill
```

**Keyboard Maestro Integration:**
The process management features make it perfect for hotkey toggles. Use `--status` to check if running, `--kill` to stop, and `--daemon` to start in background.

<details>
<summary>See the output of <code>voice-assistant --help</code></summary>

<!-- CODE:BASH:START -->
<!-- echo '```yaml' -->
<!-- export NO_COLOR=1 -->
<!-- export TERM=dumb -->
<!-- voice-assistant --help -->
<!-- echo '```' -->
<!-- CODE:END -->

<!-- OUTPUT:START -->
<!-- ⚠️ This content is auto-generated by `markdown-code-runner`. -->
```yaml
usage: voice-assistant [-h] [--log-level {DEBUG,INFO,WARNING,ERROR}]
                       [--log-file LOG_FILE] [-q]
                       [--device-index DEVICE_INDEX] [--list-devices]
                       [--asr-server-ip ASR_SERVER_IP]
                       [--asr-server-port ASR_SERVER_PORT] [--model MODEL]
                       [--ollama-host OLLAMA_HOST]

Interact with clipboard text via a voice command using Wyoming and an Ollama LLM.

This script combines functionalities from transcribe.py and autocorrect_ollama.py.

WORKFLOW:
1. The script starts and immediately copies the current content of the clipboard.
2. It then starts listening for a voice command via the microphone.
3. The user triggers a stop signal (e.g., via a Keyboard Maestro hotkey sending SIGINT).
4. The script stops recording and finalizes the transcription of the voice command.
5. It sends the original clipboard text and the transcribed command to a local LLM.
6. The LLM processes the text based on the instruction (either editing it or answering a question).
7. The resulting text is then copied back to the clipboard.

KEYBOARD MAESTRO INTEGRATION:
To create a hotkey toggle for this script, set up a Keyboard Maestro macro with:

1. Trigger: Hot Key (e.g., Cmd+Shift+A for "Assistant")

2. If/Then/Else Action:
   - Condition: Shell script returns success
   - Script: pgrep -f "voice_clipboard_assistant\.py" > /dev/null

3. Then Actions (if process is running):
   - Display Text Briefly: "🗣️ Processing command..."
   - Execute Shell Script: pkill -INT -f "voice_clipboard_assistant\.py"
   - (The script will show its own "Done" notification)

4. Else Actions (if process is not running):
   - Display Text Briefly: "📋 Listening for command..."
   - Execute Shell Script:
     #!/bin/zsh
     source "$HOME/.dotbins/shell/zsh.sh" 2>/dev/null || true  # Adds uv to PATH
     ${HOME}/dotfiles/scripts/voice_clipboard_assistant.py --device-index 1 --quiet &
   - Select "Display results in a notification"

options:
  -h, --help            show this help message and exit
  --log-level {DEBUG,INFO,WARNING,ERROR}
                        Set logging level.
  --log-file LOG_FILE   Path to a file to write logs to.
  -q, --quiet           Suppress console output from rich.
  --device-index DEVICE_INDEX
                        Index of the PyAudio input device to use.
  --list-devices        List available audio input devices and exit.
  --asr-server-ip ASR_SERVER_IP
                        Wyoming ASR server IP address.
  --asr-server-port ASR_SERVER_PORT
                        Wyoming ASR server port.
  --model MODEL, -m MODEL
                        The Ollama model to use. Default is devstral:24b.
  --ollama-host OLLAMA_HOST
                        The Ollama server host. Default is
                        http://pc.local:11434.
```

<!-- OUTPUT:END -->

</details>


## Development

### Running Tests

The project uses `pytest` for testing. To run tests using `uv`:

```bash
uv run pytest
```

### Pre-commit Hooks

This project uses pre-commit hooks (ruff for linting and formatting, mypy for type checking) to maintain code quality. To set them up:

1. Install pre-commit:

   ```bash
   pip install pre-commit
   ```

2. Install the hooks:

   ```bash
   pre-commit install
   ```

   Now, the hooks will run automatically before each commit.

## Contributing

Contributions are welcome! If you find a bug or have a feature request, please open an issue. If you'd like to contribute code, please fork the repository and submit a pull request.

## License

This project is licensed under the MIT License - see the `LICENSE` file for details.
