# Docker Compose for agent-cli Whisper ASR server
#
# Usage (pre-built images from GHCR):
#   # CUDA (GPU)
#   docker compose -f docker/docker-compose.whisper.yml --profile cuda up
#
#   # CPU only
#   docker compose -f docker/docker-compose.whisper.yml --profile cpu up
#
# Build from source (instead of using pre-built):
#   docker compose -f docker/docker-compose.whisper.yml --profile cuda up --build
#   docker compose -f docker/docker-compose.whisper.yml --profile cpu up --build

services:
  whisper-cuda:
    image: ghcr.io/basnijholt/agent-cli-whisper:latest-cuda
    build:
      context: ..
      dockerfile: docker/whisper.Dockerfile
      target: cuda
    profiles: [cuda]
    ports:
      - "10300:10300"  # Wyoming protocol
      - "10301:10301"  # HTTP API
    volumes:
      - whisper-cache:/home/whisper/.cache
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3}
      - WHISPER_TTL=${WHISPER_TTL:-300}
      - WHISPER_LOG_LEVEL=${WHISPER_LOG_LEVEL:-info}
      - WHISPER_DEVICE=cuda
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    # For NixOS or other CDI-based Docker setups, replace the `deploy` section with:
    #   devices:
    #     - nvidia.com/gpu=0    # Single GPU (use nvidia.com/gpu=all for all GPUs)
    restart: unless-stopped

  whisper-cpu:
    image: ghcr.io/basnijholt/agent-cli-whisper:latest-cpu
    build:
      context: ..
      dockerfile: docker/whisper.Dockerfile
      target: cpu
    profiles: [cpu]
    ports:
      - "10300:10300"  # Wyoming protocol
      - "10301:10301"  # HTTP API
    volumes:
      - whisper-cache:/home/whisper/.cache
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-small}
      - WHISPER_TTL=${WHISPER_TTL:-300}
      - WHISPER_LOG_LEVEL=${WHISPER_LOG_LEVEL:-info}
      - WHISPER_DEVICE=cpu
    restart: unless-stopped

volumes:
  whisper-cache:
